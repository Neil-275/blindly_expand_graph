{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a979b867",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c83eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from expand_subgraph import ExpandSubgraph\n",
    "from model import GNN_auto\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import torch\n",
    "from load_data import DataLoader\n",
    "from reasoning_module import ReasoningModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9121a6ef",
   "metadata": {},
   "source": [
    "## Load graph artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a4fb899",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"knowledge_graph/KG_data/FB15k-237-betae/id2ent.pkl\", \"rb\") as f:\n",
    "    id2ent = pkl.load(f)\n",
    "with open(\"knowledge_graph/KG_data/FB15k-237-betae/id2rel.pkl\", \"rb\") as f:\n",
    "    id2rel = pkl.load(f)\n",
    "with open(\"knowledge_graph/KG_data/FB15k-237-betae/ent2id.pkl\", \"rb\") as f:\n",
    "    ent2id = pkl.load(f)\n",
    "\n",
    "with open(\"knowledge_graph/queries/train_all_id.pkl\", \"rb\") as f:\n",
    "    queries = pkl.load(f)\n",
    "\n",
    "with open(\"knowledge_graph/KG_data/FB15k-237-betae/FB15k_mid2name.txt\", \"r\", encoding='utf-8') as f:\n",
    "    ent2name = {}\n",
    "    for line in f:\n",
    "        mid, name = line.strip().split(\"\\t\", 1)  # Use maxsplit=1 in case name has tabs\n",
    "        ent2name[mid] = name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40471fa7",
   "metadata": {},
   "source": [
    "#### Load queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cdfc7422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_type': ('e', ('r',)),\n",
       " 'raw_query': (4542, (24,)),\n",
       " 'named_query': ('And_Starring_Pancho_Villa_as_Himself',\n",
       "  ('+/award/award_winning_work/awards_won./award/award_honor/award_winner',)),\n",
       " 'transformed_query': ['Who won awards for their work starring Pancho Villa as Himself?',\n",
       "  \"Which award winner is associated with the work 'And Starring Pancho Villa as Himself'?\",\n",
       "  \"Can you tell me who received awards for 'And Starring Pancho Villa as Himself'?\"],\n",
       " 'answers_id': [3297],\n",
       " 'answers': ['Larry_Gelbart'],\n",
       " 'natural_query': 'Who won an award for their work on the film \"And Starring Pancho Villa as Himself\"?'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"knowledge_graph/queries/CWQ_sim_queries.pkl\", \"rb\") as f:\n",
    "    queries = pkl.load(f)\n",
    "id_query = 32\n",
    "queries[id_query]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ef0a4",
   "metadata": {},
   "source": [
    "## Load sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd3b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    data_path = 'knowledge_graph/KG_data/FB15k-237-betae'\n",
    "    seed = 1234\n",
    "    k = 9 # beams\n",
    "    depth = 2 # max depth of subgraph\n",
    "    cands_lim = 1024\n",
    "    gpu = 0\n",
    "    fact_ratio = 1.0\n",
    "    val_num = -1 # how many triples are used as the validate set\n",
    "    add_manual_edges = False\n",
    "    remove_1hop_edges = True\n",
    "    not_shuffle_train = False\n",
    "    device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a2f9be6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> removing 1-hop links...\n",
      "==> done\n"
     ]
    }
   ],
   "source": [
    "args = Config()\n",
    "loader = DataLoader(args, mode='train')\n",
    "\n",
    "# loader.shuffle_train()\n",
    "train_graph = loader.train_graph\n",
    "train_graph_homo = list(set([(h,t) for (h,r,t) in train_graph]))\n",
    "\n",
    "args.n_ent = loader.n_ent\n",
    "args.n_rel = loader.n_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "61a8a458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544230"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a61c8",
   "metadata": {},
   "source": [
    "### Init sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e3b8efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GoG_args = {\n",
    "    'drop_ratio': 0.4,\n",
    "}\n",
    "\n",
    "sampler = ExpandSubgraph(\n",
    "    args.n_ent, args.n_rel, train_graph_homo, train_graph, args,\n",
    "    GoG_simulation=True,\n",
    "    GoG_args=GoG_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fac5991c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating GoG by removing edges...\n"
     ]
    }
   ],
   "source": [
    "sampler.assign_query(queries[id_query])\n",
    "subgraph_data = sampler.sampleSubgraphBFS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "15f1b44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544230 544227\n"
     ]
    }
   ],
   "source": [
    "print(len(sampler.orignal_edge_index), len(sampler.edge_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "01a4524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_path_to_ans(id_query, subgraph_data):\n",
    "    for ans in queries[id_query]['answers_id']:\n",
    "        cnt = 0\n",
    "        for edges in subgraph_data[2]:\n",
    "            if ans in edges[[0,2]]:\n",
    "                cnt += 1\n",
    "        print(ans, cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5c74f2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3297 3\n"
     ]
    }
   ],
   "source": [
    "count_path_to_ans(id_query, subgraph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9af04bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7213,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(subgraph_data[2][:,[0,2]].flatten()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "401813d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_edges = subgraph_data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83cbea8",
   "metadata": {},
   "source": [
    "Check coverage of the subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd6b646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage =  1.0\n"
     ]
    }
   ],
   "source": [
    "coverage = 0\n",
    "ans = torch.tensor(queries[id_query]['answers_id'])\n",
    "subgraph_nodes = subgraph_data[0]\n",
    "## How many ans entity appear in subgraph_nodes\n",
    "mask = torch.isin(ans, subgraph_nodes)\n",
    "\n",
    "# Count how many are True\n",
    "print(\"Coverage = \", mask.sum().item() / ans.size(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fe2142",
   "metadata": {},
   "source": [
    "### Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4618b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.n_rel=237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e314dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"weights/topk_0.1_layer_8_ValMRR_0.437.pt\"\n",
    "checkpoint = torch.load(modelPath, map_location=torch.device(\"cuda:0\"))\n",
    "params = {'lr': 0.0003, 'hidden_dim': 64, 'attn_dim': 4, 'n_layer': 8, 'act': 'relu', 'initializer': 'binary', 'concatHidden': True, 'shortcut': False, 'readout': 'linear', 'decay_rate': 0.9429713470775948, 'lamb': 0.000946516892415447, 'dropout': 0.19456805575101324}\n",
    "class Model_Params:\n",
    "    n_ent = args.n_ent\n",
    "    n_rel = args.n_rel\n",
    "    lr = 0.0003\n",
    "    hidden_dim = 64\n",
    "    attn_dim = 4\n",
    "    n_layer = 8\n",
    "    act = 'relu'\n",
    "    initializer = 'binary'\n",
    "    concatHidden = True\n",
    "    shortcut = False\n",
    "    readout = 'linear'\n",
    "    decay_rate = 0.9429713470775948\n",
    "    lamb = 0.000946516892415447\n",
    "    dropout = 0.19456805575101324\n",
    "\n",
    "model_params = Model_Params()\n",
    "\n",
    "gnn_model = GNN_auto(model_params, loader)\n",
    "gnn_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "gnn_model = gnn_model.to(torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2652b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_module = ReasoningModule(queries[id_query], \n",
    "                                   sampler,\n",
    "                                   subgraph_data,\n",
    "                                   gnn_model,\n",
    "                                   \"gpt-3.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e495ee",
   "metadata": {},
   "source": [
    "### Inference on your queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7fc64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_path_to_ans(id_query, subgraph_data):\n",
    "    sum_cnt = 0\n",
    "    for ans in queries[id_query]['answers_id']:\n",
    "        cnt = 0\n",
    "        for edges in subgraph_data[2]:\n",
    "            if ans in edges[[0,2]]:\n",
    "                cnt += 1\n",
    "        sum_cnt += cnt\n",
    "        print(ent2name[id2ent[ans]], \"|| count: \" + str(cnt))\n",
    "        return sum_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c27ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "ground_truths = []\n",
    "cands = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbabc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which awards have the production companies of films featuring Katherine Heigl been nominated for?\n",
      "Simulating GoG by removing edges...\n",
      "decision:  Yes\n",
      "___________________________\n",
      "Use grounded relations.\n",
      "_____________________\n",
      "Processing relation: +/award/award_nominee/award_nominations./award/award_nomination/nominated_for\n",
      "@@@@@@@@@@@@@@  \n",
      " Top candidates from GNN:\n",
      "Killers | score:  11.432977676491602\n",
      "Knocked_Up | score:  11.432977676491602\n",
      "Grey's_Anatomy | score:  11.432977676491602\n",
      "Life_as_We_Know_It | score:  11.432977676491602\n",
      "The_Ugly_Truth | score:  11.432977676491602\n",
      "The_Haunting | score:  1.4329771996544434\n",
      "valid entity pruning\n",
      "############\n",
      " Top candidates after LLM filtering:\n",
      "The_Haunting | score:  0.7164885999272217\n",
      "Killers | score:  1e-10\n",
      "Knocked_Up | score:  1e-10\n",
      "_____________________\n",
      "Processing relation: +/award/award_nominee/award_nominations./award/award_nomination/award\n",
      "@@@@@@@@@@@@@@  \n",
      " Top candidates from GNN:\n",
      "Razzie_Award_for_Worst_Actress | score:  10.982972145180566\n",
      "Screen_Actors_Guild_Award_for_Outstanding_Performance_by_an_Ensemble_in_a_Drama_Series | score:  10.982972145180566\n",
      "Richard_Donner | score:  0.8787789941834045\n",
      "Peter_Morgan | score:  0.8432437182472778\n",
      "Alex_Kurtzman | score:  0.7533308864639832\n",
      "Colin_Wilson | score:  0.7411521078156067\n",
      "valid entity pruning\n",
      "############\n",
      " Top candidates after LLM filtering:\n",
      "Colin_Wilson | score:  0.37057605400780336\n",
      "Razzie_Award_for_Worst_Actress | score:  1e-10\n",
      "Screen_Actors_Guild_Award_for_Outstanding_Performance_by_an_Ensemble_in_a_Drama_Series | score:  1e-10\n",
      "Not yet found the answer, continue searching...\n",
      "Info: [(5320, 76, 5099), (5320, 38, 8064), (5320, 76, 3656)]\n",
      "decision:  No\n",
      "___________________________\n",
      "Use predicted relations.\n",
      "_____________________\n",
      "Processing relation: +/film/film/executive_produced_by\n",
      "@@@@@@@@@@@@@@  \n",
      " Top candidates from GNN:\n",
      "Jan_de_Bont | score:  11.504124641518457\n",
      "Samuel_Z._Arkoff | score:  11.504124641518457\n",
      "Dressed_to_Kill | score:  0.4086546004818512\n",
      "X-Men | score:  1e-10\n",
      "Stan_Lee | score:  1e-10\n",
      "Fantastic_Four:_Rise_of_the_Silver_Surfer | score:  1e-10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m reasoning_module.assign_query(query)\n\u001b[32m      6\u001b[39m reasoning_module.assign_subgraph(subgraph_data)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mreasoning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m results = reasoning_module.result\n\u001b[32m      9\u001b[39m predictions.append([results])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:49\u001b[39m, in \u001b[36mreasoning\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\code\\research\\messing_around\\prototype\\reasoning_module.py:344\u001b[39m, in \u001b[36mfilter_cands\u001b[39m\u001b[34m(self, candidate_ids, query, entity_id, relation, scores, m_candidates, args)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;66;03m#########\u001b[39;00m\n\u001b[32m    343\u001b[39m entity_candidates = [ent2name[id2ent[candidate_id]] \u001b[38;5;28;01mfor\u001b[39;00m candidate_id \u001b[38;5;129;01min\u001b[39;00m candidate_ids]\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m prompt = construct_entity_score_prompt(query[\u001b[33m'\u001b[39m\u001b[33mnatural_query\u001b[39m\u001b[33m'\u001b[39m], relation, entity_candidates, scores)\n\u001b[32m    345\u001b[39m result = run_llm(prompt, engine=args)\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# print(res_entity[0])\u001b[39;00m\n\u001b[32m    347\u001b[39m \u001b[38;5;66;03m# print(\"A: \", entity_candidates)\u001b[39;00m\n\u001b[32m    348\u001b[39m \u001b[38;5;66;03m# print(\"B:\", res_entity)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\code\\research\\messing_around\\prototype\\utils.py:91\u001b[39m, in \u001b[36mrun_llm\u001b[39m\u001b[34m(prompt, system_prompt, max_tokens, temperature, engine, sub_objective)\u001b[39m\n\u001b[32m     89\u001b[39m         result = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m     90\u001b[39m     \u001b[38;5;66;03m# break\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     time.sleep(\u001b[32m1\u001b[39m)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for query in queries[::]:\n",
    "    ground_truths.append(query['answers'])\n",
    "    print(query['natural_query'])\n",
    "    subgraph_data = sampler.sampleSubgraph(query)\n",
    "    \n",
    "    # reasoning_module.assign_query(query)\n",
    "    # reasoning_module.assign_subgraph(subgraph_data)\n",
    "    # reasoning_module.reasoning()\n",
    "    # results = reasoning_module.result\n",
    "    # predictions.append([results])\n",
    "    # cands.append(reasoning_module.cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb53575",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bdc112",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_t = {\"predctions\": predictions, \"cands\": cands, \"ground_truths\": ground_truths}\n",
    "\n",
    "with open(\"attempt_4_1_100_queries.pkl\", \"wb\") as f:\n",
    "    pkl.dump(dict_t, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a436146e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.0, 'f1': 0.0, 'hit@1': 0.0, 'hit@3': 0.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate_result import evaluate_predictions\n",
    "\n",
    "evaluate_predictions(ground_truths, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10015f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5320]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_module.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df81f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Razzie_Award_for_Worst_Picture || count: 0\n",
      "Academy_Award_for_Best_Picture || count: 0\n",
      "Tony_Award_for_Best_Musical || count: 0\n",
      "Razzie_Award_for_Worst_Prequel,_Remake,_Rip-off_or_Sequel || count: 0\n",
      "Satellite_Award_for_Best_Animated_or_Mixed_Media_Feature || count: 0\n"
     ]
    }
   ],
   "source": [
    "count_path_to_ans(1,  subgraph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f42499c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_type': ('e', ('r', 'r', 'r')),\n",
       " 'raw_query': (5320, (12, 172, 38)),\n",
       " 'named_query': ('Katherine_Heigl',\n",
       "  ('+/film/actor/film./film/performance/film',\n",
       "   '+/film/film/production_companies',\n",
       "   '+/award/award_nominee/award_nominations./award/award_nomination/award')),\n",
       " 'transformed_query': ['Which awards have been associated with films that Katherine Heigl acted in?',\n",
       "  'What are the film awards received or nominated for by movies featuring Katherine Heigl?',\n",
       "  'Can you list the awards for which the films starring Katherine Heigl have been nominated?'],\n",
       " 'answers_id': [929, 1121, 2859, 1808, 3646],\n",
       " 'answers': ['Razzie_Award_for_Worst_Picture',\n",
       "  'Academy_Award_for_Best_Picture',\n",
       "  'Tony_Award_for_Best_Musical',\n",
       "  'Razzie_Award_for_Worst_Prequel,_Remake,_Rip-off_or_Sequel',\n",
       "  'Satellite_Award_for_Best_Animated_or_Mixed_Media_Feature'],\n",
       " 'natural_query': 'Which awards have the production companies of films featuring Katherine Heigl been nominated for?'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ida",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
